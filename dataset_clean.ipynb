{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\achia\\anaconda3\\envs\\llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, load_from_disk\n",
    "import torchvision.transforms as transforms\n",
    "import json\n",
    "from PIL import Image\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/coco/annotations/captions_train2017.json\",'r') as fh:\n",
    "    raw_train_data = json.load(fh)\n",
    "with open(\"data/coco/annotations/captions_val2017.json\",'r') as fh:\n",
    "    raw_val_data = json.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(raw_train_data[\"annotations\"])\n",
    "train_df.drop_duplicates(subset=['image_id'], inplace=True)\n",
    "# train_df = train_df[:25000]\n",
    "val_df = pd.DataFrame(raw_val_data[\"annotations\"])\n",
    "val_df.drop_duplicates(subset=['image_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_image_id_to_image(image_id, split='train'):\n",
    "    image_folder = f'data/coco/{split}2017/'\n",
    "    # format image id with leading zeros\n",
    "    filename = \"\"\n",
    "    for i in range(12-len(str(image_id))):\n",
    "        filename += '0'\n",
    "    filename += str(image_id)\n",
    "    formatted_image_id = re.sub(r'^(\\d+)$', lambda x: x.group(1).zfill(6), filename)\n",
    "    image_filename = f\"{formatted_image_id}.JPG\"  # Assuming the file extension is '.jpeg'\n",
    "    return os.path.join(image_folder, image_filename)\n",
    "\n",
    "# Apply the function to create the new column\n",
    "train_df['img_path'] = train_df['image_id'].apply(map_image_id_to_image)\n",
    "train_df['is_file'] = train_df['img_path'].apply(lambda x : os.path.isfile(x))\n",
    "train_df = train_df[train_df['is_file'] == True]\n",
    "val_df['img_path'] = val_df['image_id'].apply(lambda x: map_image_id_to_image(x, split='val'))\n",
    "val_df['is_file'] = val_df['img_path'].apply(lambda x : os.path.isfile(x))\n",
    "val_df = val_df[val_df['is_file'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#         [transforms.ToTensor(),\n",
    "#         transforms.Resize((128, 128)),\n",
    "#         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "def preprocess_img(data_entry):\n",
    "    raw  = Image.open(data_entry['img_path']).convert(\"RGB\")\n",
    "#     processed = transform(raw)\n",
    "#     return {'raw_image': raw, 'img': processed}\n",
    "    return {'raw_image': raw}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 118287/118287 [3:50:31<00:00,  8.55 examples/s]  \n",
      "Saving the dataset (115/115 shards): 100%|██████████| 118287/118287 [04:35<00:00, 429.37 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "val_dataset = Dataset.from_pandas(val_df, preserve_index=False)\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_img)\n",
    "train_dataset.save_to_disk(\"processed_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5000/5000 [08:36<00:00,  9.68 examples/s]  \n",
      "Saving the dataset (5/5 shards): 100%|██████████| 5000/5000 [00:04<00:00, 1202.31 examples/s]\n"
     ]
    }
   ],
   "source": [
    "val_dataset = val_dataset.map(preprocess_img)\n",
    "val_dataset.save_to_disk(\"processed_val\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
